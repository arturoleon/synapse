{
    "statusCode": 200,
    "headers": {
        "Date": "Tue, 22 Oct 2024 01:37:05 GMT",
        "Content-Type": "application\/json",
        "Content-Length": "779",
        "Connection": "keep-alive",
        "access-control-expose-headers": "X-Request-ID",
        "openai-organization": "user-5hvzt3x5aqwr0picqhxifwl8",
        "openai-processing-ms": "1096",
        "openai-version": "2020-10-01",
        "x-ratelimit-limit-requests": "10000",
        "x-ratelimit-limit-tokens": "2000000",
        "x-ratelimit-remaining-requests": "9999",
        "x-ratelimit-remaining-tokens": "1999888",
        "x-ratelimit-reset-requests": "6ms",
        "x-ratelimit-reset-tokens": "3ms",
        "x-request-id": "req_021c6924d94bd0e3ee0f06bc3db4c4bc",
        "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
        "CF-Cache-Status": "DYNAMIC",
        "Set-Cookie": [
            "__cf_bm=vL__r5ubJvNV4RmlJZhNFqArDwX6GyxVKpi.q4yM0nI-1729561025-1.0.1.1-UpZdTgW2r55OFqoyho_c5ivHOoQRN8ljHmOPcECcUNlMcWmNp6zCSPvljzEVxxSgqJC6yW8kTDEo16cfyjxN8g; path=\/; expires=Tue, 22-Oct-24 02:07:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None",
            "_cfuvid=8YjaCofLksiUzxQCu0C5XWrc1Q8tEXkO1xPJxxx0MkQ-1729561025666-0.0.1.1-604800000; path=\/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None"
        ],
        "X-Content-Type-Options": "nosniff",
        "Server": "cloudflare",
        "CF-RAY": "8d65c292d9c11a38-EWR",
        "alt-svc": "h3=\":443\"; ma=86400"
    },
    "data": "{\n  \"id\": \"chatcmpl-AKy7Uc6De3D1gSPOHQZTYrQkiA2Ek\",\n  \"object\": \"chat.completion\",\n  \"created\": 1729561024,\n  \"model\": \"gpt-4-turbo-2024-04-09\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"The user's message says \\\"hello this a test\\\" and the assistant responds with \\\"hello this a test\\\". The user then asks what they just said, but backwards.\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 93,\n    \"completion_tokens\": 34,\n    \"total_tokens\": 127,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  },\n  \"system_fingerprint\": \"fp_eae715ec6a\"\n}\n"
}